# In a nutshell:
We created a multimodal emotion identification tool to examine the emotions of job candidates. 

Deep learning algorithms are used to assess face, vocal, and textual emotions. We built a web 
application with Flask.

ğ—™ğ—¼ğ—¿ ğ—©ğ—¶ğ—±ğ—²ğ—¼ ğ—œğ—»ğ˜ğ—²ğ—¿ğ˜ƒğ—¶ğ—²ğ˜„:
- Use the video interview simulator to see how our technology understands 
your facial expressions in comparison to other applicants.

ğ—™ğ—¼ğ—¿ ğ—”ğ˜‚ğ—±ğ—¶ğ—¼ ğ—œğ—»ğ˜ğ—²ğ—¿ğ˜ƒğ—¶ğ—²ğ˜„:
- Use the Audio Interview Simulator to see how our technology understands 
your voice emotions in comparison to other applicants.

ğ—™ğ—¼ğ—¿ ğ—§ğ—²ğ˜…ğ˜ ğ—œğ—»ğ˜ğ—²ğ—¿ğ˜ƒğ—¶ğ—²ğ˜„: 
- Use the Text Interview Simulator to see how our technology evaluates your 
Psychological qualities in comparison to other applicants.

# How to use it ?
There are several resources available :

- the working notebooks can be found in the Text/Video/Audio sections
- the final notebooks can be accessed through the Google Colab link in the table at the beginning

To use the web app :

- Clone the project locally

- Go in the WebApp folder

- Run `$ pip install -r requirements.txt`

- Launch ``` python app.py ```
